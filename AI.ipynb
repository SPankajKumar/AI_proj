{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5048,"databundleVersionId":868335,"sourceType":"competition"},{"sourceId":408355,"sourceType":"datasetVersion","datasetId":181839}],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import concat\nimport numpy as np\nfrom numpy import concatenate\nfrom math import sqrt\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-27T18:05:25.433060Z","iopub.execute_input":"2024-03-27T18:05:25.433423Z","iopub.status.idle":"2024-03-27T18:05:28.197805Z","shell.execute_reply.started":"2024-03-27T18:05:25.433394Z","shell.execute_reply":"2024-03-27T18:05:28.196974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_folder=\"/kaggle/input/state-farm-distracted-driver-detection/\"\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:28.199652Z","iopub.execute_input":"2024-03-27T18:05:28.200311Z","iopub.status.idle":"2024-03-27T18:05:28.205048Z","shell.execute_reply.started":"2024-03-27T18:05:28.200275Z","shell.execute_reply":"2024-03-27T18:05:28.203971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder_path='/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv'\ndf = pd.read_csv(folder_path)\nprint(len(df.index))","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:28.207388Z","iopub.execute_input":"2024-03-27T18:05:28.208129Z","iopub.status.idle":"2024-03-27T18:05:28.260081Z","shell.execute_reply.started":"2024-03-27T18:05:28.208095Z","shell.execute_reply":"2024-03-27T18:05:28.259132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#folder_path='/kaggle/input/revitsone-5class/Revitsone-5classes'\n#df1 = pd.read_csv(folder_path)\n#print(len(df1.index))","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:28.262100Z","iopub.execute_input":"2024-03-27T18:05:28.262395Z","iopub.status.idle":"2024-03-27T18:05:28.266452Z","shell.execute_reply.started":"2024-03-27T18:05:28.262369Z","shell.execute_reply":"2024-03-27T18:05:28.265505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pickle\nimport datetime\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D, \\\n                                       ZeroPadding2D,Conv2D\n\nfrom keras.utils import to_categorical \n\n\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom keras.models import model_from_json\nfrom numpy.random import permutation\n\nimport keras\nimport keras.backend as K \nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Add, Input, BatchNormalization, Activation\nfrom keras.layers import  Conv2D, MaxPooling2D, AveragePooling2D, Flatten\nfrom keras.regularizers import l2\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport glob\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\n\n%matplotlib inline\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:28.267609Z","iopub.execute_input":"2024-03-27T18:05:28.267891Z","iopub.status.idle":"2024-03-27T18:05:39.607874Z","shell.execute_reply.started":"2024-03-27T18:05:28.267868Z","shell.execute_reply":"2024-03-27T18:05:39.606960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/state-farm-distracted-driver-detection/driver_imgs_list.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:39.609179Z","iopub.execute_input":"2024-03-27T18:05:39.610357Z","iopub.status.idle":"2024-03-27T18:05:39.635888Z","shell.execute_reply.started":"2024-03-27T18:05:39.610321Z","shell.execute_reply":"2024-03-27T18:05:39.634942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:39.636977Z","iopub.execute_input":"2024-03-27T18:05:39.637239Z","iopub.status.idle":"2024-03-27T18:05:39.652157Z","shell.execute_reply.started":"2024-03-27T18:05:39.637217Z","shell.execute_reply":"2024-03-27T18:05:39.651224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"by_drivers = df.groupby('subject')\nunique_drivers = by_drivers.groups.keys()\nprint(unique_drivers)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:39.653204Z","iopub.execute_input":"2024-03-27T18:05:39.653454Z","iopub.status.idle":"2024-03-27T18:05:39.671428Z","shell.execute_reply.started":"2024-03-27T18:05:39.653431Z","shell.execute_reply":"2024-03-27T18:05:39.670564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUMBER_CLASSES=10\ntrain_images = [] \ntrain_labels = []\ndef load_train(img_rows, img_cols, color_type=3):\n   \n\n    for classed in tqdm(range(NUMBER_CLASSES)):\n        print(format(classed))\n        files = glob.glob(os.path.join('../input/state-farm-distracted-driver-detection/imgs/train/c' + str(classed), '*.jpg'))\n        for file in files:\n            img_cv = cv2.imread(file)\n            img_cv_r = cv2.resize(img_cv,(128,128))            \n            train_images.append(img_cv_r)\n            train_labels.append(classed)\n    return train_images, train_labels ","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:39.672593Z","iopub.execute_input":"2024-03-27T18:05:39.672946Z","iopub.status.idle":"2024-03-27T18:05:39.679561Z","shell.execute_reply.started":"2024-03-27T18:05:39.672918Z","shell.execute_reply":"2024-03-27T18:05:39.678727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cv2_image(path, img_rows, img_cols, color_type=3):\n \n    if color_type == 1:\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    elif color_type == 3: \n        img = cv2.imread(path, cv2.IMREAD_COLOR)\n    img = cv2.resize(img, (img_rows, img_cols))\n    return img","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:39.682917Z","iopub.execute_input":"2024-03-27T18:05:39.683184Z","iopub.status.idle":"2024-03-27T18:05:39.693337Z","shell.execute_reply.started":"2024-03-27T18:05:39.683162Z","shell.execute_reply":"2024-03-27T18:05:39.692335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n\ndef resize_and_normalize_train_data(img_rows, img_cols, color_type):\n\n    X, labels = load_train(img_rows, img_cols, color_type)\n    y = to_categorical(labels, 10) #categorical train label\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # split into train and test\n    x_train = np.array(x_train, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    x_test = np.array(x_test, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    \n    return x_train, x_test, y_train, y_test","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:39.694703Z","iopub.execute_input":"2024-03-27T18:05:39.695090Z","iopub.status.idle":"2024-03-27T18:05:39.705363Z","shell.execute_reply.started":"2024-03-27T18:05:39.695056Z","shell.execute_reply":"2024-03-27T18:05:39.704514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_test(size=200000, img_rows=64, img_cols=64, color_type=3):\n    \n    path = os.path.join('../input/state-farm-distracted-driver-detection/imgs/test', '*.jpg')\n    files = sorted(glob.glob(path))\n    X_test, X_test_id = [], []\n    total = 0\n    files_size = len(files)\n    for file in tqdm(files):\n        if total >= size or total >= files_size:\n            break\n        file_base = os.path.basename(file)\n        img = get_cv2_image(file, img_rows, img_cols, color_type)\n        X_test.append(img)\n        X_test_id.append(file_base)\n        total += 1\n    return X_test, X_test_id","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:39.706354Z","iopub.execute_input":"2024-03-27T18:05:39.706971Z","iopub.status.idle":"2024-03-27T18:05:39.713570Z","shell.execute_reply.started":"2024-03-27T18:05:39.706947Z","shell.execute_reply":"2024-03-27T18:05:39.712819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def resize_and_normalize_test_data(size, img_rows, img_cols, color_type=3):\n    test_data, test_ids = load_test(size, img_rows, img_cols, color_type)   \n    test_data = np.array(test_data, dtype=np.uint8)\n    test_data = test_data.reshape(-1,img_rows,img_cols,color_type)\n    return test_data, test_ids","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:39.714536Z","iopub.execute_input":"2024-03-27T18:05:39.714794Z","iopub.status.idle":"2024-03-27T18:05:39.724279Z","shell.execute_reply.started":"2024-03-27T18:05:39.714772Z","shell.execute_reply":"2024-03-27T18:05:39.723497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_rows = 128 \nimg_cols = 128\ncolor_type =3 \nnb_test_samples = 200\n\nx_train, x_test, y_train, y_test = resize_and_normalize_train_data(img_rows, img_cols, color_type)\n\ntest_files, test_targets = resize_and_normalize_test_data(nb_test_samples, img_rows, img_cols, color_type)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:39.725327Z","iopub.execute_input":"2024-03-27T18:05:39.725562Z","iopub.status.idle":"2024-03-27T18:11:54.390789Z","shell.execute_reply.started":"2024-03-27T18:05:39.725542Z","shell.execute_reply":"2024-03-27T18:11:54.389853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnames = [item[17:19] for item in sorted(glob.glob(\"../input/state-farm-distracted-driver-detection/imgs/train/*/\"))]\ntest_files_size = len(np.array(glob.glob(os.path.join('../input/state-farm-distracted-driver-detection/imgs/test', '*.jpg'))))\nx_train_size = len(x_train)\ncategories_size = len(names)\nx_test_size = len(x_test)\nprint('total images',(test_files_size + x_train_size + x_test_size))\nprint(' training images',x_train_size)\nprint(' total training categories',categories_size)\nprint(' validation images',x_test_size)\nprint('test images',test_files_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:11:54.392045Z","iopub.execute_input":"2024-03-27T18:11:54.392331Z","iopub.status.idle":"2024-03-27T18:11:54.703176Z","shell.execute_reply.started":"2024-03-27T18:11:54.392307Z","shell.execute_reply":"2024-03-27T18:11:54.702257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nimport plotly.express as px\n\npx.histogram(df, x=\"classname\", color=\"classname\", title=\"Number of images by categories \")","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:11:54.704417Z","iopub.execute_input":"2024-03-27T18:11:54.704736Z","iopub.status.idle":"2024-03-27T18:11:56.308195Z","shell.execute_reply.started":"2024-03-27T18:11:54.704704Z","shell.execute_reply":"2024-03-27T18:11:56.307225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drivers_id = pd.DataFrame((df['subject'].value_counts()).reset_index())\ndrivers_id.columns = ['driver_id', 'Counts']\npx.histogram(drivers_id, x=\"driver_id\",y=\"Counts\" ,color=\"driver_id\", title=\"Number of images by subjects \")","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:11:56.309723Z","iopub.execute_input":"2024-03-27T18:11:56.310017Z","iopub.status.idle":"2024-03-27T18:11:56.512568Z","shell.execute_reply.started":"2024-03-27T18:11:56.309992Z","shell.execute_reply":"2024-03-27T18:11:56.511650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drivers_id = pd.DataFrame((df['subject'].value_counts()).reset_index())\ndrivers_id.columns = ['driver_id', 'Counts']\ndrivers_id","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:11:56.513860Z","iopub.execute_input":"2024-03-27T18:11:56.514253Z","iopub.status.idle":"2024-03-27T18:11:56.531809Z","shell.execute_reply.started":"2024-03-27T18:11:56.514217Z","shell.execute_reply":"2024-03-27T18:11:56.530637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"activity_map = {'c0': 'Safe driving', \n                'c1': 'Texting - right', \n                'c2': 'Talking on the phone - right', \n                'c3': 'Texting - left', \n                'c4': 'Talking on the phone - left', \n                'c5': 'Operating the radio', \n                'c6': 'Drinking', \n                'c7': 'Reaching behind', \n                'c8': 'Hair and makeup', \n                'c9': 'Talking to passenger'}","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:11:56.533097Z","iopub.execute_input":"2024-03-27T18:11:56.533428Z","iopub.status.idle":"2024-03-27T18:11:56.539970Z","shell.execute_reply.started":"2024-03-27T18:11:56.533402Z","shell.execute_reply":"2024-03-27T18:11:56.538895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.image as mpimg\n\nplt.figure(figsize = (10, 20))\nimage_count = 1\nBASE_URL = '../input/state-farm-distracted-driver-detection/imgs/train/'\nfor directory in os.listdir(BASE_URL):\n    if directory[0] != '.':\n        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n            if i == 1:\n                break\n            else:\n                fig = plt.subplot(5, 2, image_count)\n                image_count += 1\n                image = mpimg.imread(BASE_URL + directory + '/' + file)\n                plt.imshow(image)\n                plt.title(activity_map[directory])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:11:56.541049Z","iopub.execute_input":"2024-03-27T18:11:56.541320Z","iopub.status.idle":"2024-03-27T18:11:59.761919Z","shell.execute_reply.started":"2024-03-27T18:11:56.541292Z","shell.execute_reply":"2024-03-27T18:11:59.760727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''def create_model():\n    model = Sequential()\n\n    model.add(Conv2D(filters = 64, kernel_size = 3, padding='same', activation = 'relu', input_shape=(img_rows, img_cols, color_type)))\n    model.add(MaxPooling2D(pool_size = 2))\n\n    model.add(Conv2D(filters = 128, padding='same', kernel_size = 3, activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = 2))\n\n    model.add(Conv2D(filters = 256, padding='same', kernel_size = 3, activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = 2))\n\n    model.add(Conv2D(filters = 512, padding='same', kernel_size = 3, activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = 2))\n\n    model.add(Dropout(0.5))\n\n    model.add(Flatten())\n\n    model.add(Dense(500, activation = 'relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation = 'softmax'))\n    \n    return model'''","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:11:59.763148Z","iopub.execute_input":"2024-03-27T18:11:59.763451Z","iopub.status.idle":"2024-03-27T18:11:59.770725Z","shell.execute_reply.started":"2024-03-27T18:11:59.763426Z","shell.execute_reply":"2024-03-27T18:11:59.769701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ncnn_model = Sequential()\ncnn_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64,1)))\ncnn_model.add(layers.MaxPooling2D((2, 2)))\ncnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\ncnn_model.add(layers.MaxPooling2D((2, 2)))\ncnn_model.add(layers.Conv2D(128, (3, 3), activation='relu'))\ncnn_model.add(layers.MaxPooling2D((2, 2)))\ncnn_model.add(layers.Conv2D(128, (3, 3), activation='relu'))\ncnn_model.add(layers.MaxPooling2D((2, 2)))\ncnn_model.add(layers.Flatten())\ncnn_model.add(layers.Dense(128, activation='relu'))\ncnn_model.add(layers.Dense(10, activation='softmax'))'''","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:11:59.772010Z","iopub.execute_input":"2024-03-27T18:11:59.772315Z","iopub.status.idle":"2024-03-27T18:11:59.783405Z","shell.execute_reply.started":"2024-03-27T18:11:59.772288Z","shell.execute_reply":"2024-03-27T18:11:59.782548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.Sequential()\n\nmodel.add(keras.layers.InputLayer(\n    input_shape=(128, 128, 3)\n))\n\nmodel.add(\n    keras.layers.Conv2D(\n        filters=32,\n        kernel_size=(5,5),\n        strides = (1,1),\n        padding='same',\n        activation='relu',\n        name='Conv_1'))\n\nmodel.add(\n    keras.layers.MaxPool2D(\n        pool_size = (2,2),\n        name = 'Pool_1'))\nmodel.add(\n    keras.layers.Conv2D(\n        filters = 64,\n        kernel_size = (5,5),\n        strides = (1,1),\n        padding = 'same',\n        activation = 'relu',\n        name = 'Conv_2'))\n\nmodel.add(\n    keras.layers.MaxPool2D(\n        pool_size = (2,2),\n        name = 'Pool_2'))\n\nmodel.add(\n    keras.layers.Conv2D(\n        filters = 128,\n        kernel_size = (5,5),\n        strides = (1,1),\n        padding = 'same',\n        activation = 'relu',\n        name = 'Conv_3'))\n\nmodel.add(\n    keras.layers.MaxPool2D(\n        pool_size = (2,2),\n        name = 'Pool_3'))\n\nmodel.add(\n    keras.layers.Conv2D(\n        filters = 256,\n        kernel_size = (5,5),\n        strides = (1,1),\n        padding = 'same',\n        activation = 'relu',\n        name = 'Conv_4'))\n\nmodel.add(\n    keras.layers.MaxPool2D(\n        pool_size = (2,2),\n        name = 'Pool_4'))\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(units=1024, activation='relu',name = 'fc_1'))\nmodel.add(keras.layers.Dropout(rate=0.2))\nmodel.add(keras.layers.Dense(units=512, activation='relu',name = 'fc_2'))\nmodel.add(keras.layers.Dense(units=10,activation='softmax',name = 'fc_3'))\n#model.compute_output_shape(input_shape=(256,8,8,1))","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:11:59.784557Z","iopub.execute_input":"2024-03-27T18:11:59.784875Z","iopub.status.idle":"2024-03-27T18:12:00.567301Z","shell.execute_reply.started":"2024-03-27T18:11:59.784849Z","shell.execute_reply":"2024-03-27T18:12:00.566337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''def create_model():\n    model=Sequential()\n    model.add(Conv2D(32,(3,3),activation='relu',input_shape=(img_rows, img_cols, color_type)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.5))\n    \n    ## Output\n    model.add(Flatten())\n    model.add(Dense(512,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(10,activation='softmax'))\n\n    return model'''","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:12:00.568747Z","iopub.execute_input":"2024-03-27T18:12:00.569364Z","iopub.status.idle":"2024-03-27T18:12:00.576364Z","shell.execute_reply.started":"2024-03-27T18:12:00.569322Z","shell.execute_reply":"2024-03-27T18:12:00.575460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.summary()\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:12:00.577638Z","iopub.execute_input":"2024-03-27T18:12:00.577992Z","iopub.status.idle":"2024-03-27T18:12:00.622179Z","shell.execute_reply.started":"2024-03-27T18:12:00.577962Z","shell.execute_reply":"2024-03-27T18:12:00.621474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x = x_train, y=y_train,epochs = 10, batch_size = 128, verbose = 1,validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:12:00.623227Z","iopub.execute_input":"2024-03-27T18:12:00.623509Z","iopub.status.idle":"2024-03-27T18:13:23.219682Z","shell.execute_reply.started":"2024-03-27T18:12:00.623485Z","shell.execute_reply":"2024-03-27T18:13:23.218841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_train_history(history):\n  \n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    \nplot_train_history(history)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:13:23.221086Z","iopub.execute_input":"2024-03-27T18:13:23.221374Z","iopub.status.idle":"2024-03-27T18:13:23.692563Z","shell.execute_reply.started":"2024-03-27T18:13:23.221349Z","shell.execute_reply":"2024-03-27T18:13:23.691588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score1 = model.evaluate(x_test, y_test, verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:13:23.697345Z","iopub.execute_input":"2024-03-27T18:13:23.697619Z","iopub.status.idle":"2024-03-27T18:13:27.586431Z","shell.execute_reply.started":"2024-03-27T18:13:23.697596Z","shell.execute_reply":"2024-03-27T18:13:27.585338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Loss: ', score1[0])\nprint('Accuracy: ', score1[1]*100, ' %')","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:13:27.587850Z","iopub.execute_input":"2024-03-27T18:13:27.588149Z","iopub.status.idle":"2024-03-27T18:13:27.594910Z","shell.execute_reply.started":"2024-03-27T18:13:27.588124Z","shell.execute_reply":"2024-03-27T18:13:27.593717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_test_class(model, test_files, image_number):\n   \n    img_brute = test_files[image_number]\n    img_brute = cv2.resize(img_brute,(img_rows,img_cols))\n    plt.imshow(img_brute)\n\n    new_img = img_brute.reshape(-1,img_rows,img_cols,color_type)\n   \n    y_prediction = model.predict(new_img, batch_size=32, verbose=1)\n    predicted_class = np.argmax(y_prediction)\n    print('Predicted: {}'.format(activity_map.get('c{}'.format(np.argmax(y_prediction)))))\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:13:27.596472Z","iopub.execute_input":"2024-03-27T18:13:27.596819Z","iopub.status.idle":"2024-03-27T18:13:27.604253Z","shell.execute_reply.started":"2024-03-27T18:13:27.596783Z","shell.execute_reply":"2024-03-27T18:13:27.603223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    plot_test_class(model, test_files, i)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:13:27.605403Z","iopub.execute_input":"2024-03-27T18:13:27.605796Z","iopub.status.idle":"2024-03-27T18:13:31.771774Z","shell.execute_reply.started":"2024-03-27T18:13:27.605760Z","shell.execute_reply":"2024-03-27T18:13:31.770836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense\nfrom keras.models import Model\nimport keras\nfrom keras import layers\n\ninput_img = keras.Input(shape=(128, 128, 3))\n\nx = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = layers.MaxPooling2D((2, 2), padding='same')(x)\nx = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = layers.MaxPooling2D((2, 2), padding='same')(x)\nx = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n\n\nx = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\nx = layers.UpSampling2D((2, 2))(x)\nx = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = layers.UpSampling2D((2, 2))(x)\nx = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = layers.UpSampling2D((2, 2))(x)\ndecoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = keras.Model(input_img, decoded)\nautoencoder.compile(optimizer='adam', loss='mean_squared_error')","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:13:31.773044Z","iopub.execute_input":"2024-03-27T18:13:31.773313Z","iopub.status.idle":"2024-03-27T18:13:31.853732Z","shell.execute_reply.started":"2024-03-27T18:13:31.773289Z","shell.execute_reply":"2024-03-27T18:13:31.852945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:13:31.854720Z","iopub.execute_input":"2024-03-27T18:13:31.854996Z","iopub.status.idle":"2024-03-27T18:13:31.882787Z","shell.execute_reply.started":"2024-03-27T18:13:31.854972Z","shell.execute_reply":"2024-03-27T18:13:31.881900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nautoencoder.fit(x_train, x_train,\n                epochs=25,\n                batch_size=32,\n                shuffle=True,\n                validation_data=(x_test, x_test))","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:13:31.883693Z","iopub.execute_input":"2024-03-27T18:13:31.883942Z","iopub.status.idle":"2024-03-27T18:15:37.455348Z","shell.execute_reply.started":"2024-03-27T18:13:31.883921Z","shell.execute_reply":"2024-03-27T18:15:37.454358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's see how the loss are changing for test and validation set\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:15:37.456524Z","iopub.execute_input":"2024-03-27T18:15:37.456844Z","iopub.status.idle":"2024-03-27T18:15:37.686874Z","shell.execute_reply.started":"2024-03-27T18:15:37.456813Z","shell.execute_reply":"2024-03-27T18:15:37.685928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dec_x_test = autoencoder.predict(x_test, verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:15:37.688141Z","iopub.execute_input":"2024-03-27T18:15:37.688945Z","iopub.status.idle":"2024-03-27T18:15:40.652848Z","shell.execute_reply.started":"2024-03-27T18:15:37.688917Z","shell.execute_reply":"2024-03-27T18:15:40.651984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n = 10\nplt.figure(figsize=(20, 4))\n\nfor i in range(1, n+1, 1):\n    ax = plt.subplot(2, n, i)\n    plt.imshow(x_test[i * 10])\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # Display reconstruction:\n    ax = plt.subplot(2, n, i+n)\n    plt.imshow(dec_x_test[i *10])\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:15:40.654198Z","iopub.execute_input":"2024-03-27T18:15:40.654486Z","iopub.status.idle":"2024-03-27T18:15:41.787570Z","shell.execute_reply.started":"2024-03-27T18:15:40.654462Z","shell.execute_reply":"2024-03-27T18:15:41.786622Z"},"trusted":true},"execution_count":null,"outputs":[]}]}